{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install fast-autocomplete\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sentence-transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install stanfordnlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install editdistance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install lupyne","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pylucene4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nimport random\nimport editdistance\nimport stanfordnlp as st\nimport spacy \nfrom fast_autocomplete import AutoComplete\nfrom fast_autocomplete import autocomplete_factory\nimport json\n\nimport re\nfrom nltk.corpus import stopwords\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom tqdm import tqdm\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"st.download('en')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"queries_df = pd.read_csv('../input/ms-marco-queries/msmarco-doctrain-queries.tsv', sep = '\\t', names = ['qid','query'])\nqueries_df = queries_df.set_index('qid')\ndisplay(queries_df.head(10))\ndisplay(queries_df.tail(10))\nprint(len(queries_df.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('./')) # This will print the content of current directory\nprint(os.listdir('../input')) # This will print the content of input directory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Install and import relevant libraries\n!python -m easy_install ../input/compiledlucene/bk/lucene-8.1.1-py3.6-linux-x86_64.egg\n!cp -r ../input/compiledlucene/bk/JCC-3.7-py3.6-linux-x86_64.egg /opt/conda/lib/python3.6/site-packages/\nimport sys\nsys.path\nsys.path.append('/opt/conda/lib/python3.6/site-packages/JCC-3.7-py3.6-linux-x86_64.egg')\nsys.path.append('/opt/conda/lib/python3.6/site-packages/lucene-8.1.1-py3.6-linux-x86_64.egg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lucene","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's first check for any null rows\n\nnull_rows = queries_df[queries_df.isnull().any(axis = 1)]\ndisplay(null_rows)\n\n# Cool, there aren't any","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's try to find the average length of a query\n\ndef return_length(n):\n    return len(n)\n\ntotal_len = np.sum(queries_df['query'].apply(return_length))\naverage_query_length = total_len/len(queries_df)\nprint(total_len)\nprint(average_query_length)\n\n# 33 characters seems reasonable.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average number of word counts in the query\n\ndef number_of_words(n):\n    words = n.split(' ')\n    return len(words)\n\ntotal_word_count = np.sum(queries_df['query'].apply(number_of_words))\naverage_word_count = total_word_count/len(queries_df)\nprint(total_word_count)\nprint(average_word_count)\n\n# An average word count of 6 seems about right for a query","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's now create a corpus of the 2.1M words used in the queries\n\ndef build_vocab(sentences, verbose =  True):\n    vocab = {}\n    for sentence in tqdm(sentences, disable = (not verbose)):\n        for word in sentence.split(' '):\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab\n\nsentences = queries_df['query'].values\n# print(sentences)\nvocab = build_vocab(sentences)\nprint({k: vocab[k] for k in list(vocab)[:5]})\n\n# As we can see, there are some tokens that are misspelled. I'll have to handle that later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's now sort the vocab, that way we can remove the mispelled words\n\nsorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n\n# Let's first the see the top 10 most common words in the text, and their counts\nprint(sorted_vocab[:5])\n\n# Let's now have a look at the last 50 terms in the sorted list (they will most probably be mispellings)\nprint(sorted_vocab[-50:])\n\n\n# WOAH!! This is surprising, the last items of the sorted list, aren't actually mispelling, but many of them are just words ending with a question mark or bracket. I am gonna leave them be for now.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Phaze 0. Evaluation Metrics *(& Supporting Functions)*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def query_sampler(df, percentage_of_samples = 0.9):\n    \"\"\" \n    This function creates a sample set of queries from the orignal dataset\n    \n    Args:\n        df (dataframe) -> The original dataframe\n        percentage_of_samples (float) -> Between 0 and 1\n        \n    Returns:\n        Sampled set of queries.\n    \n    \"\"\"\n    l = len(df)\n    number_of_samples = int(l*percentage_of_samples)\n    print(\"Number of instances being sampled is\", number_of_samples)\n    randomList = random.sample(range(0, l), number_of_samples)\n    return(df.iloc[randomList])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def break_the_query(query_string):\n    \"\"\"\n    This function breaks the query down on character level.\n    \n    Args:\n        query_string(str) -> Original query string\n        \n    Returns:\n        list_of_strings(iterable) -> A list of multiple sub-strings made from the query\n    \"\"\"\n    list_of_strings = []\n    l = len(query_string)\n    for i in range (1, l-1):\n        s = query_string[:i]\n        list_of_strings.append(s)\n    return list_of_strings\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(df, train_percentage = 0.9):\n    \"\"\" \n    This function creates a sample set of queries from the orignal dataset\n    \n    Args:\n        df (dataframe) -> The original dataframe\n        train_percentage (float) -> Represents the percentage of training examples. Between 0 and 1\n        \n    Returns:\n        Training and testing data\n    \n    \"\"\"\n    l = len(df)\n    number_of_training_samples = int(l*train_percentage)\n    print(\"Number of instances being sampled for training data is\", number_of_training_samples)\n    train_List = random.sample(range(0, l), number_of_training_samples)\n    test_List = []\n    for i in range(l):\n        if i not in train_List:\n            test_List.append(i)\n    return(df.iloc[train_List], df.iloc[test_List])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distance Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"def distance_score(str1, str2):\n    \"\"\"\n    This function calculates the Levenshtein distance between the two strings. Will use the library 'editdistance' for this task.\n    \n    Args:\n        str1(string) -> String 1\n        str2(string) -> String 2\n        \n    Returns:\n        d (float) -> Represents the leveshtein distance between the two strings\n    \"\"\"\n    d = editdistance.eval(str1, str2)\n    return d\n\ndef best_distance_on_query(model, query_string):\n    \"\"\"\n    This function returns the best distance score from all the suggestions made for a query.\n    \n    Args:\n        model (object) -> Trained model object \n        query_string (string) -> The query string\n        \n    Returns:\n        Best Levenshtein distance score of all the suggestions made by the model.\n    \"\"\"\n    query_suggestions = model.getAutoSuggestions(query_string)\n    least_distance = len(query_string) * 5\n    for query_suggestion in query_suggestions:\n        distance_measure = distance_score(query_suggestion, query_string)\n        if distance_measure < least_distance:\n            least_distance = distance_measure\n    return least_distance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Relevance Scores\n\nI will evaluate Relevance score by evaluating the cosine distance between word embeddings of the query suggestions and the original query."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(raw_text):\n    # keep only words\n    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n\n    # convert to lower case and split \n    words = letters_only_text.lower().split()\n\n    # remove stopwords\n    stopword_set = set(stopwords.words(\"english\"))\n    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n    \n    # remove the words we do not have an embedding for\n    #preprocessed_words = list(set([w for w in cleaned_words if w in list(model_5.keys())]))\n    preprocessed_words = cleaned_words\n\n    return preprocessed_words\n\ndef bert_cosine_distance_on_sentences(vector_1, s2):\n    #sentence_list_1 = preprocess(s1)\n    sentence_list_2 = preprocess(s2)\n    #sentence_1 = ''\n    sentence_2 = ''\n    #for word in sentence_list_1:\n        #sentence_1 += word\n        #sentence_1 += ' '\n    #sentence_1 = sentence_1[:-1]\n    for word in sentence_list_2:\n        sentence_2 += word\n        sentence_2 += ' '\n    sentence_2 = sentence_2[:-1]\n    #vector_1 = model_5.encode(sentence_1)\n    vector_2 = model_5.encode(sentence_2)\n    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n    # print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1-cosine)*100,2),'%')\n    return cosine\n\ndef evaluate_bert_cosine_distance_on_query_suggestions(query_string, query_suggestions):\n    \"\"\"\n    This function finds the BERT cosine distance between the actual query and the query suggestions made by the model\n    \n    Args:\n        query_string (string) -> The original query string\n        query_suggestions (list) -> List of strings containing the suggestions.\n        \n    Returns:\n        cosine_distance (float) -> The smallest cosine distance between the query strings and the \n    \n    \"\"\"\n    predicted_similarity = []\n    cosine_distance = []\n    bert_original_query_vector = model_5.encode(query_string)\n    for i in range(len(query_suggestions)):\n        #print(df.iloc[i, 1])\n        #print(type(df.iloc[i, 1]))\n        cosine_distance_between_sentences = bert_cosine_distance_on_sentences(bert_original_query_vector, query_suggestions[i])\n        cosine_distance.append(cosine_distance_between_sentences)\n    #scaler = MinMaxScaler()\n    cosine_distance = np.array(cosine_distance)\n    return cosine_distance\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_5 = SentenceTransformer('bert-base-nli-mean-tokens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Phaze 1. AutoSuggest Methods"},{"metadata":{},"cell_type":"markdown","source":"## Part 1: Dictionary Based Approach"},{"metadata":{},"cell_type":"markdown","source":"#### Preparing Data\nIdeally the dictionary-based approach (without analyzers) shouldn't include words in the build dictionary, but I am gonna try it out as well. \nSo, the data would be prepared for TRIE in two batches:\n1. Simple queries data.\n2. Simple queries data, along with all the words used in that queries data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell contains the point 1 of the two data forms described above.\n\n#First I am gonna create a sample of ~36000 queries\nqueries_df_1 = query_sampler(queries_df, percentage_of_samples = 0.1)\n\n# Next up, I'll remove the qid from the index\nqueries_df_1.reset_index(drop = True, inplace = True)\n\n# Next I'll divide the queries data into train and test set. With 95% training data\ntrain_queries_df_1, test_queries_df_1 = train_test_split(queries_df_1, train_percentage = 0.95)\ntrain_queries_data_1 = train_queries_df_1['query'].values\ntest_queries_data_1 = test_queries_df_1['query'].values\nprint(train_queries_data_1)\nprint(len(train_queries_data_1))\n#print(queries_data_1)\n#print(len(queries_data_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell contains data created by definition of point 2 of the two data forms described above.\n\n#First I am gonna create a sample of ~36000 queries\nqueries_df_2 = query_sampler(queries_df, percentage_of_samples = 0.1)\n\n# Next up, I'll remove the qid from the index\nqueries_df_2.reset_index(drop = True, inplace = True)\n\n# Next up I am gonna add all the words in these queries seperately as well\nsentences = queries_df_2['query'].values\ntokens = []\nfor sentence in tqdm(sentences):\n    for word in sentence.split(' '):\n        # I will also have to remove the special characters from the words before putting them into the vocab. I will not remove numerics because many search queries might require numbers like WC20 or XL5 etc\n        token = \"\"\n        for character in word:\n            if character.isalnum():\n                token += character\n        tokens.append(token)\nvocab = list(set(tokens))\nfor word in vocab:\n    queries_df_2 = queries_df_2.append({'query' : word}, ignore_index=True)\n    \ndisplay(queries_df_2.tail(10))\ndisplay(len(queries_df_2))\n\n# Next I'll divide the queries data into train and test set. With 95% training data\ntrain_queries_df_2, test_queries_df_2 = train_test_split(queries_df_2, train_percentage = 0.95)\ntrain_queries_data_2 = train_queries_df_2['query'].values\ntest_queries_data_2 = test_queries_df_2['query'].values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Creation: TRIE"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrieNode(): \n    def __init__(self): \n          \n        # Initialising one node for trie \n        self.children = {} \n        self.last = False\n  \n\nclass Trie(): \n    def __init__(self): \n          \n        # Initialising the trie structure. \n        self.root = TrieNode() \n        self.word_list = []\n        self.count = 0\n  \n    def formTrie(self, keys): \n          \n        # Forms a trie structure with the given set of strings \n        # if it does not exists already else it merges the key \n        # into it by extending the structure as required \n        for key in keys: \n            self.insert(key) # inserting one key to the trie. \n  \n    def insert(self, key): \n          \n        # Inserts a key into trie if it does not exist already. \n        # And if the key is a prefix of the trie node, just  \n        # marks it as leaf node. \n        node = self.root \n  \n        for a in list(key): \n            if not node.children.get(a): \n                node.children[a] = TrieNode() \n  \n            node = node.children[a] \n  \n        node.last = True\n  \n    def search(self, key): \n          \n        # Searches the given key in trie for a full match \n        # and returns True on success else returns False. \n        node = self.root \n        found = True\n  \n        for a in list(key): \n            if not node.children.get(a): \n                found = False\n                break\n  \n            node = node.children[a] \n  \n        return node and node.last and found \n  \n    def suggestionsRec(self, node, word): \n          \n        # Method to recursively traverse the trie \n        # and return a whole word.  \n        if node.last: \n            self.word_list.append(word) \n  \n        for a,n in node.children.items(): \n            self.suggestionsRec(n, word + a)\n            \n    def limitedSuggestionsRec(self, node, word, no_of_suggestions): \n          \n        # Method to recursively traverse the trie \n        # and return a whole word. But limit the number of routes ventured to no_of_suggestions\n        if node.last:\n            self.count = self.count + 1\n            if self.count <= no_of_suggestions:\n                self.word_list.append(word)\n\n        for a,n in node.children.items():\n            self.suggestionsRec(n, word + a) \n            \n    \n    def printAutoSuggestions(self, key, no_of_suggestions = 0): \n        # Returns all the words in the trie whose common \n        # prefix is the given key thus listing out all  \n        # the suggestions for autocomplete. \n        node = self.root \n        not_found = False\n        temp_word = '' \n        print('This function was called')\n        characters = list(key)\n        for a in characters:\n            if not node.children.get(a): \n                not_found = True\n                break\n  \n            temp_word += a \n            node = node.children[a] \n  \n        if not_found: \n            return 0\n        elif node.last and not node.children: \n            return -1\n  \n        if no_of_suggestions>0:\n            self.count = 0\n            self.limitedSuggestionsRec(node, temp_word, no_of_suggestions)\n        else:\n            self.suggestionsRec(node, temp_word)\n  \n        for s in self.word_list: \n            print(s) \n        return 1\n    \n    def getAutoSuggestions(self, key, no_of_suggestions = 0): \n          \n        # Returns all the words in the trie whose common \n        # prefix is the given key thus listing out all  \n        # the suggestions for autocomplete. \n        node = self.root \n        not_found = False\n        temp_word = '' \n  \n        characters = list(key)\n        for a in characters:\n            if not node.children.get(a): \n                not_found = True\n                break\n  \n            temp_word += a \n            node = node.children[a] \n  \n        if not_found: \n            return 0\n        elif node.last and not node.children: \n            return -1\n        \n        if no_of_suggestions>0:\n            self.count = 0\n            self.limitedSuggestionsRec(node, temp_word, no_of_suggestions)\n        else:\n            self.suggestionsRec(node, temp_word)\n   \n        return self.word_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Training\nWe are gonna create two TRIE structures (one for each kind of data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1 = Trie()\nmodel_1.formTrie(train_queries_data_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = Trie()\nmodel_2.formTrie(train_queries_data_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Testing\nWe are gonna test each of the two models trained above using 3 metrics of evaluation:\n1. Intuition Based (Will analyze the relevance of the search suggestions manually)\n2. Distance Based (Will produce the overall score of test set using Levenshtein Distance)\n3. Relevance Based (Will use semantic textual similarity to determine relevance of each of the suggestions)."},{"metadata":{},"cell_type":"markdown","source":"##### Model 1:"},{"metadata":{},"cell_type":"markdown","source":"1. **Intuition Based**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I am first gonna define the three strings I'll be using for Intuition based testing\nstring1 = 'What building method might use a balloon frame?'\nstring2 = 'What is causing rash on arms'\nstring3 = 'What causes your glands on the top of your throat to swell'\n\n# Next up, I am gonna create a list of sub strings from these queries\nlist_string1 = break_the_query(string1)\nlist_string2 = break_the_query(string2)\nlist_string3 = break_the_query(string3)\n\n# Now, I'll print the query results after each new character being typed in\ncomp = model_1.printAutoSuggestions(string1) \nif comp == -1: \n    print(\"No other strings found with this prefix\\n\") \nelif comp == 0: \n    print(\"No string found with this prefix\\n\") \nbreak\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **Distance Scoring**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. **Relevance Scoring**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 2: Analyzer Based Approach"},{"metadata":{},"cell_type":"markdown","source":"#### Data Preparation\nI am gonna prepare the data with the following steps:\n1. Tokenize the data\n2. Create a Dictionary of Words, and their contexts."},{"metadata":{"trusted":true},"cell_type":"code","source":"#First I am gonna create a sample of ~36000 queries\nqueries_df_3 = query_sampler(queries_df, percentage_of_samples = 0.1)\n\n# Next up, I'll remove the qid from the index\nqueries_df_3.reset_index(drop = True, inplace = True)\ndisplay(queries_df_3.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The problem with this data is that it cannot be used for NER tasks as it is, that is, it is not capitalized. And therefore, will not be able to identify NER tags properly.\n# To resolve this problem, we will perform manual True Casing by using POS tagger of StanfordNLP, and then the results thus produced would be fed into SpaCy NER model.\n\n# Initialize the StanfordNLP pipeline, and instantiate the spacy english models\nstf_nlp = st.Pipeline(processors='tokenize,mwt,pos')\nspacy_nlp = spacy.load('en_core_web_sm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Custom_Analyzer:\n    \"\"\"\n    This class performs several analysis on the query data (NER, POS, etc.) and creates a word dictionary of a form appropriate for usage in fast-autocomplete library\n    \n    Args:\n        df (DataFrame) -> Contains all the queries\n        \n    Returns:\n        words (dictionary) -> Dictionary of the fast-autocomplete prescribed format\n    \n    \"\"\"\n    def __init__(self, df):\n        self.words = {}\n        self.df = df\n        \n        \n    def get_entities(self, query_string):\n        '''\n        This function takes in the query string and returns all the Named Entities present in the caseless string being passed to it.\n        \n        Args:\n            query_string (string) -> A single query of the user\n            \n        Returns:\n            ner_word_values (list) -> Contains all the identified NER terms in the text, along with their corresponding tag and start and end points (of words, not characters).\n        \n        '''\n        #print(query_string)\n        \n        # Here, I'll first perform Truecasing using StanfordNLP, and then use NER model from Spacy\n        doc = stf_nlp(query_string)\n        truecased_list = [w.text.capitalize() if w.upos in [\"PROPN\",\"NNS\"] else w.text for sent in doc.sentences for w in sent.words]\n        truecased_query = ''\n        for word in truecased_list:\n            truecased_query += str(word)\n            truecased_query += ' '\n        truecased_query = truecased_query[:-1]\n        doc = spacy_nlp(truecased_query)\n        ner_values = []\n        for ent in doc.ents: \n            #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n            ner_values.append([ent.text, ent.start_char, ent.end_char, ent.label_])\n        \n        # The following code maps the character position of entitites recognized to the word position.\n        char_to_word_mapping = []\n        j = 1\n        start_char_position = 0\n        end_char_position = 0\n        for i in range(len(query_string)):\n            if len(list(query_string.split(' '))) == 1:\n                end_char_position = len(query_string) - 1\n                char_to_word_mapping.append([start_char_position, end_char_position, j])\n                break\n            if query_string[i] == ' ':\n                end_char_position = i-1\n                char_to_word_mapping.append([start_char_position, end_char_position, j])\n                start_char_position = i + 1\n                j = j+1\n        ner_word_values = []\n        for i in range(len(ner_values)):\n            ner_word = ner_values[i][0]\n            ner_word_label = ner_values[i][3]\n            ner_word_position_start = 0 \n            ner_word_position_end = 0\n            for k in range(len(char_to_word_mapping)):\n                if char_to_word_mapping[k][0] == ner_values[i][1]:\n                    ner_word_position_start = char_to_word_mapping[k][2]\n                if ner_values[i][2] == char_to_word_mapping[k][1] + 1:\n                    ner_word_position_end = char_to_word_mapping[k][2]\n            ner_word_values.append([ner_word, ner_word_position_start, ner_word_position_end, ner_word_label])\n        return ner_word_values\n\n        \n        \n    def add_new_word_to_dictionary(self, current_word, prior1_word = None, prior2_word = None, ner_context = None):\n        '''\n        This function adds a new word/phraze to the words dictionary\n        \n        Args:\n            current_word (string) -> A token (word/phraze) to be added to the dictionary\n            ner_context (string) -> Describes the type of entity, if there is one\n            prior1_word (string) -> The word immediately prior to the current one\n            prior2_word (string) -> The word before the prior1_word\n        \n        '''\n        self.words[current_word] = []              # Initializing the word in words dictionary\n        self.words[current_word].append({})           # Initializing the Context dictionary for that word\n        self.words[current_word].append(current_word)         # Setting the display value equal to the word string\n        self.words[current_word].append(1)            # Initializing the Count to be equal to zero\n        if prior1_word != None:\n            self.words[current_word][0][\"priorone\"] = prior1_word\n        if prior2_word != None:\n            self.words[current_word][0][\"priortwo\"] = prior2_word\n        if ner_context != None:\n            self.words[current_word][0][\"type\"] = ner_context \n        # Write the code for adding a POS tag value to the context of each current_word. Will have to decide whether or not I want to do this.\n     \n    \n    def check_whether_in_dictionary(self, current_word, prior1_word = None, prior2_word = None, ner_context = None):\n        '''\n        This function checks whether a word, along with all its contexts, exists in a dictionary. It overlooks differences due to absence of NER tags in one of the words.\n        \n        Args:\n            current_word (string) -> The string to be checked for within the words dictionary\n            ner_context (string) -> Describes the type of entity, if there is one\n            prior1_word (string) -> The word immediately prior to the current one\n            prior2_word (string) -> The word before the prior1_word            \n        Returns:\n            is_in (int) -> 0 for not in dictionary, 1 for in dictionary but different context, 2 for in dictionary same context\n        \n        '''\n        is_in = 0\n        \n        # Ignore context for recognized entities\n        if ner_context != None:\n            if current_word not in self.words:\n                return is_in\n            else:\n                self.words[current_word][2] += 1\n                is_in = 2\n                return is_in\n                \n        # But if the word is not a recognized entity, then the context would be considered.\n        if current_word not in self.words:\n            is_in = 0\n            return is_in\n        context_of_existing_current_word = self.words[current_word][0]\n        existing_context_list = context_of_existing_current_word.keys()\n        new_word_context = {}\n        if prior1_word != None:\n            new_word_context[\"priorone\"] = prior1_word\n        if prior2_word != None:\n            new_word_context[\"priortwo\"] = prior2_word\n        #if ner_context != None:\n            #new_word_context[\"type\"] = ner_context\n    \n        # Following code checks whether the word has been used in the same context or not\n        same = True\n        for context in existing_context_list:\n            if context in new_word_context.keys():\n                if new_word_context[context] == context_of_existing_current_word[context]:\n                    same = True\n                else:\n                    same = False\n                    break\n        if same == True:\n            self.words[current_word][2] += 1           # Increasing the count of the word by one\n            is_in = 2\n        else:\n            is_in = 1\n        return is_in\n\n        \n    \n    def get_words_dictionary(self, context_size = 1):\n        \"\"\"\n        This function creates a dictionary of words in the format that can be directly fed into fast-autocomplete model.\n\n        Args:\n            context_size (int) -> The size of the context window to be turned into the dictionary format.\n            \n        Returns:\n            words (dictionary) -> Dictionary of words in the format required by fast-autocomplete model.\n        \"\"\"\n        for i in range(len(self.df)):\n            query = self.df['query'][i]\n            ner_word_values = self.get_entities(query_string = query)\n            # ner_word_values_df = pd.DataFrame(ner_word_values)\n            query_words = query.split(' ')\n            ner_under_play = 0\n            for j in range(len(query_words)):\n                ner_context = None\n                prior1_word = None\n                if (j-1) >= 0:\n                    prior1_word = query_words[j-1]\n                #if (j-2) >= 0:\n                    #prior2_word = query_words[j-2]\n                \n                # The following code extracts the entire entity recognized as 1 word, otherwise follows the conventional path for extraction of word\n                if len(ner_word_values) > 0:\n                    if (j+1) == ner_word_values[ner_under_play][1]:\n                        j_start = j\n                        j_end = ner_word_values[ner_under_play][2]\n                        current_word = ''\n                        for k in range(j_start, j_end):\n                            current_word += query_words[k]\n                            current_word += ' '\n                        current_word = current_word[:-1]\n                        ner_context = ner_word_values[ner_under_play][3]\n                        j = j_end - 1\n                        if ner_under_play+1 < len(ner_word_values):\n                            ner_under_play += 1\n                    else:\n                        current_word = query_words[j]\n                else:\n                    current_word = query_words[j]\n                \n                # The following code updates the dictionary on the basis that NER words are added as it is, and non-recognized words are checked for context\n                if ner_context != None:\n                    word_check = self.check_whether_in_dictionary(current_word)\n                    if word_check == 2:\n                        continue\n                    else:\n                        self.add_new_word_to_dictionary(current_word, prior1_word, ner_context = ner_context)\n                \n                else:\n                    word_check = self.check_whether_in_dictionary(current_word)\n                    if word_check == 2:\n                        continue\n                    elif word_check == 0:\n                        self.add_new_word_to_dictionary(current_word, prior1_word)\n                    else:\n                        check_flag = True\n                        additional_words_under_consideration = 1\n                        while check_flag and (j + additional_words_under_consideration) < len(query_words):\n                            current_word = current_word.append(' ')\n                            current_word = current_word.append(query_words[j + additional_words_under_consideration])\n                            word_check = self.check_whether_in_dictionary(current_word)\n                            if word_check == 2:\n                                check_flag = False\n                            elif word_check == 0:\n                                self.add_new_word_to_dictionary(current_word, prior1_word)\n                                check_flag = False\n                            else:\n                                continue\n        return self.words\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test file\n\n'''\nstring1 = 'What building method might use a balloon frame?'\nstring2 = 'What is causing rash on arms'\nstring3 = 'What causes your glands on the top of your throat to swell'\nquery_list = ['What building method might use a balloon frame?','What is causing rash on arms', 'what does jon snow know', 'where is duke university in columbia','what causes the glands on top of your throat to swell']\nquery_df_111 = pd.DataFrame(query_list, columns = ['query'])\ndisplay(query_df_111.head(5))\n\n\ndata_generator = Custom_Analyzer(query_df_111)\nwords = data_generator.get_words_dictionary()\nprint(words)\n\n\n# Will convert the words dictionary into the appropriate .json file\nwords_json = json.dumps(words)\nwith open('temp_words.json', 'w') as json_file:\n    json.dump(words, json_file)\n\n    \ncontent_files = {\n    'words': {\n        'filepath': './temp_words.json',\n        'compress': True  # means compress the graph data in memory\n    }\n}\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here, I'll create the data, and convert it into the required format\n\n#First I am gonna create a sample of ~36000 queries\n#queries_df_3 = query_sampler(queries_df, percentage_of_samples = 0.1)\n\n# Next up, I'll remove the qid from the index\n#queries_df_3.reset_index(drop = True, inplace = True)\n\n# Next, I'll parse the data into dictionary format\ndata_generator = Custom_Analyzer(queries_df_3)\nwords = data_generator.get_words_dictionary()\nprint(words)\n\n\n# Will convert the words dictionary into the appropriate .json file\n# words_json = json.dumps(words)\nwith open('ten_percent_words.json', 'w') as json_file:\n    json.dump(words, json_file)\n\n    \ncontent_files = {\n    'words': {\n        'filepath': './ten_percent_words.json',\n        'compress': True  # means compress the graph data in memory\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Analyzer_Suggestor:\n    '''\n    This class creates the object function of the fast-autocomplete model\n    \n    '''\n    def __init__(self):\n        pass\n    \n    def general_autocomplete(self, words):\n        self.model = AutoComplete(words = words)\n        return self.model\n    \n    def factory_autocomplete(self, content_files):\n        self.model = autocomplete_factory(content_files=content_files)\n        return self.model\n    \n    def getAutoSuggestions(self, query_string):\n        return self.model.search(query_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analyzer_object = Analyzer_Suggestor()\nmodel = analyzer_object.factory_autocomplete(content_files)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Testing"},{"metadata":{},"cell_type":"markdown","source":"1. **Intuition Based**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I am first gonna define the three strings I'll be using for Intuition based testing\nstring1 = 'What building method might use a balloon frame?'\nstring2 = 'What is causing rash on arms'\nstring3 = 'What causes your glands on the top of your throat to swell'\n\n# Next up, I am gonna create a list of sub strings from these queries\nlist_string1 = break_the_query(string1)\nlist_string2 = break_the_query(string2)\nlist_string3 = break_the_query(string3)\n\n# Now, I'll print the query results after each new character being typed in\nfor partial_query_text in list_string1:\n    comp = model.search(partial_query_text)\n    print(partial_query_text)\n    print(comp)\n\nfor partial_query_text in list_string2:\n    comp = model.search(partial_query_text)\n    print(partial_query_text)\n    print(comp)\n    \nfor partial_query_text in list_string3:\n    comp = model.search(partial_query_text)\n    print(partial_query_text)\n    print(comp)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **Distance Score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. **Relevance Score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 3: Content Based Approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}